{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: This project is currently a proof of concept only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERVIEW: \n",
    "This notebook is where I'll be developing an algorithm for a twitterbot, HurriHelp to use. HurriHelp aims to connect folks tweeting using the #HurricaneIan hashtag with the National Disaster Distress Helpline (1-800-985-5990) and a link directing them to FEMA's page about Hurricane Ian (https://www.fema.gov/disaster/4673) in real time if they are in distress. The algorithm was trained on data with sentiment analysis to judge whether or not to engage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Problem: \n",
    "FEMA's twitter cannot respond to every tweet using the #HurricaneIan hashtag, and the people making those tweets need proactive information and resources. \n",
    "\n",
    "### The stakeholder:\n",
    "This algorithm is meant to serve folks who have been negatively impacted by Hurricane Ian and who are tweeting about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Case: \n",
    "<'twitter_user'> is in distress since Hurricane Ian destroyed their home. They tweet \"HurricaneIan wrecked my home of 20 years. I don't know what to do. I'm devastated.\" Within minutes, HurriHelp responds to their tweet saying \"Hi! I'm HurriHelp, a hurricane helper bot. Here's some resources. National Disaster Distress Helpline (1-800-985-5990), for more info: https://www.fema.gov/disaster/4673\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding: \n",
    "I'll be using data that I scraped from Twitter. All these tweets contained the #HurricaneIan hashtag. The data I scraped from twitter has more features than I'm able to analyze or use currently for this project, and am saving a majority of analysis about them for future work. From the scrape, I've already filtered out Retweets and duplicates, so only the original tweets remain. \n",
    "\n",
    "Of the features the following came directly from my twitter scrape: text,\tscreen_name,\tuser_description,\tfavourite_count\tretweet_count,\tcreated_at,\treplying_to\tmedia,\thashtags,\turls,\tuser_mentions,\tis_quote,\tis_retweet. Of these features I'll be using only the \"text\" for analysis and modeling. \n",
    "\n",
    "The features containing sentiment analysis: text_blob,\tbert,\tvader_compound,\tbert_label I've engineered in a previous notebook. The first step will be making a cohesive sentiment label from text_blob, bert and vader. \n",
    "\n",
    "The data contains 7653 rows, each representing an instance of an original tweet containing the #HurricaneIan hashtag. \n",
    "\n",
    "#### Limitations:\n",
    "This data is limited in that it's a small sample, compared to what's possible. I also could use a staggered sampling technique in future work. In modeling I wasn't able to get a better than 80% F1 score. It's worth investigating whether a larger amount of training data, or training data taken over a larger sample time would result in better metrics. \n",
    "\n",
    "#### Bias:\n",
    "Because I used a neural network to make my labels I will *not* be using a neural network in my modeling to avoid bias. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.800775Z",
     "start_time": "2022-11-17T07:09:06.675993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "# importing all the libraries I'll need \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import plot_roc_curve, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import spacy \n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk import FreqDist\n",
    "\n",
    "import string\n",
    "import contractions\n",
    "from cleantext import clean\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.803763Z",
     "start_time": "2022-11-17T07:09:08.802029Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.806352Z",
     "start_time": "2022-11-17T07:09:08.804951Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making an empty list to store the classification reports my models with produce\n",
    "\n",
    "reports = []\n",
    "top_20_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.809975Z",
     "start_time": "2022-11-17T07:09:08.807417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making a funciton to give me a ROC_AUC plot and classification report for \n",
    "# each model\n",
    "\n",
    "def evaluate(model, X_val, y_val, y_preds):\n",
    "    \"\"\"\n",
    "    DOCSTRING: \n",
    "    evaluate expects a model, a list of y_trues and associated list of \n",
    "    y_predicted. it outputs a confusion matrix of PRECICSION values (noramalize is\n",
    "    set to 'preds') and the associated precision, recall, f1 and support scores\n",
    "    \"\"\"\n",
    "\n",
    "    lables = ['Negative Sentiment', 'Positive Sentiment']    \n",
    "    \n",
    "    ROC_AUC = metrics.plot_roc_curve(estimator = model, X = X_val, y = y_val,\n",
    "                                     pos_label = 0)\n",
    "    \n",
    "    report = classification_report(y_val, y_preds, target_names = lables,\n",
    "                                       output_dict = False)\n",
    "\n",
    "    dict_report = classification_report(y_val, y_preds, target_names = lables,\n",
    "                                       output_dict = True)\n",
    "    reports.append(dict_report)\n",
    "    print(ROC_AUC);\n",
    "    print('************************************************************')\n",
    "    print(\"FULL REPORT\")\n",
    "    print('************************************************************')\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.822951Z",
     "start_time": "2022-11-17T07:09:08.811815Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_common(doc_string, sentiment_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    DOCSTRING: intakes a string and a sentiment name and returns a plot of the \n",
    "    most common words in that string, with the labels showing the sentiment name\n",
    "    \"\"\"\n",
    "    sns.set_style('white')\n",
    "    doc = nlp(doc_string)\n",
    "\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    freqdist = FreqDist(tokens)\n",
    "\n",
    "    most_common = freqdist.most_common(20)\n",
    "    most_common_df = pd.DataFrame(most_common)\n",
    "    most_common_df.head()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize = (8, 8))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    top_20 = sns.barplot(x = 0, y = 1, data = most_common_df, color= 'blue')\n",
    "    top_20.set_xlabel(f\"Most Common Words in {sentiment_name}\")\n",
    "    top_20.set_ylabel(\"Frequencies\")\n",
    "    top_20.set_title(\"Top 20 Words in Hurricane Ian Tweets\")\n",
    "    return most_common, top_20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.827729Z",
     "start_time": "2022-11-17T07:09:08.824103Z"
    }
   },
   "outputs": [],
   "source": [
    "def bigrams(sentiment_tokens, sentiment_name, name):\n",
    "    \n",
    "    \"\"\"\n",
    "    DOCSTRING: intakes a list of tokens and a sentiment name and returns \n",
    "    a bigram plot of the most common intersection of words in those tokens,\n",
    "    with the sentiment name labeled in the plot\n",
    "    \"\"\"\n",
    "\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(sentiment_tokens)\n",
    "    scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    top_20_bigram = pd.DataFrame(scored[:20])\n",
    "    top_20_bigram.head()\n",
    "    \n",
    "    bigrams = [str(x).strip('()').title() for x in top_20_bigram[0]]\n",
    "    top_20_bigram[0] = bigrams\n",
    "    top_20_bigram[1] = [100 * (round(float(x), ndigits = 4)) for x in top_20_bigram[1]]\n",
    "    \n",
    "    plt.figure(figsize = (8, 8))\n",
    "\n",
    "    top_20 = sns.barplot(x = 0, y = 1, data = top_20_bigram, color = 'green')\n",
    "    top_20.set_xlabel(\"Bigrams\")\n",
    "    top_20.set_ylabel(\"Frequencies in Percentages\")\n",
    "    top_20.set_title(f\"Top 20 Two-Word Combinations in {sentiment_name}\")\n",
    "    plt.xticks(rotation = 65)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{name}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.830966Z",
     "start_time": "2022-11-17T07:09:08.828717Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_word_cloud(text, name):\n",
    "    \n",
    "    \"\"\"\n",
    "    DOC STRING: intakes takes and makes a word cloud\n",
    "    \"\"\"\n",
    "\n",
    "    # Create and generate a word cloud image:\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bicubic')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.savefig(f\"{name}\")\n",
    "    \n",
    "    wordcloud.to_file(f'{name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.835351Z",
     "start_time": "2022-11-17T07:09:08.833056Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cat_preds(clf, X):\n",
    "    predict_probas = clf.predict_proba(X)\n",
    "    y_preds = []\n",
    "    for x in predict_probas:\n",
    "        if x[0] > x[1]:\n",
    "            y_preds.append(0)\n",
    "        if x[0] < x[1]:\n",
    "            y_preds.append(1)\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.920597Z",
     "start_time": "2022-11-17T07:09:08.836904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>replying_to</th>\n",
       "      <th>media</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>bert</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>bert_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“#Florida's death toll from #HurricaneIan tops...</td>\n",
       "      <td>AmPowerBlog</td>\n",
       "      <td>Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:43+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Florida', 'indices': [1, 9]}, {'tex...</td>\n",
       "      <td>[{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[{'label': 'Positive', 'score': 0.352827787399...</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republicans. can’t. be.  counted. on. to. do. ...</td>\n",
       "      <td>nivnos33</td>\n",
       "      <td>#RESISTER #Woke #Democrat #NeverGOP #VotingRig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:22+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'VoteOutEveryRepublican', 'indices':...</td>\n",
       "      <td>[{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[{'label': 'Neutral', 'score': 0.3550549745559...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leadership you can Trust. 🦟 Make sure to like ...</td>\n",
       "      <td>TrishTheCommish</td>\n",
       "      <td>#Commissioner, #Mom, #PublicServant, #Mosquito...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:09+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'text': 'leadbyexample', 'indices': [180, 19...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[{'label': 'Neutral', 'score': 0.4122076034545...</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Everyone,\\n1/3) Many Floridians face flo...</td>\n",
       "      <td>Find_and_Bind1</td>\n",
       "      <td>Amateur journalist, photographer, #bondage ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [112, 125...</td>\n",
       "      <td>[{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[{'label': 'Positive', 'score': 0.351958453655...</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lord, please be a refuge for those in need. Gi...</td>\n",
       "      <td>shellsfaith</td>\n",
       "      <td>My name is Shelly and this is where I will be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:45+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [195, 208...</td>\n",
       "      <td>[{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>[{'label': 'Neutral', 'score': 0.3944049477577...</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      screen_name  \\\n",
       "0  “#Florida's death toll from #HurricaneIan tops...      AmPowerBlog   \n",
       "1  Republicans. can’t. be.  counted. on. to. do. ...         nivnos33   \n",
       "2  Leadership you can Trust. 🦟 Make sure to like ...  TrishTheCommish   \n",
       "3  Hello Everyone,\\n1/3) Many Floridians face flo...   Find_and_Bind1   \n",
       "4  Lord, please be a refuge for those in need. Gi...      shellsfaith   \n",
       "\n",
       "                                    user_description  favourite_count  \\\n",
       "0  Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...                0   \n",
       "1  #RESISTER #Woke #Democrat #NeverGOP #VotingRig...                0   \n",
       "2  #Commissioner, #Mom, #PublicServant, #Mosquito...                2   \n",
       "3  Amateur journalist, photographer, #bondage ent...                0   \n",
       "4  My name is Shelly and this is where I will be ...                1   \n",
       "\n",
       "   retweet_count                 created_at replying_to  media  \\\n",
       "0              0  2022-10-03 20:19:43+00:00         NaN  False   \n",
       "1              0  2022-10-03 20:19:22+00:00         NaN  False   \n",
       "2              0  2022-10-03 20:19:09+00:00         NaN   True   \n",
       "3              0  2022-10-03 20:18:56+00:00         NaN  False   \n",
       "4              0  2022-10-03 20:18:45+00:00         NaN  False   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'Florida', 'indices': [1, 9]}, {'tex...   \n",
       "1  [{'text': 'VoteOutEveryRepublican', 'indices':...   \n",
       "2  [{'text': 'leadbyexample', 'indices': [180, 19...   \n",
       "3  [{'text': 'HurricaneIan', 'indices': [112, 125...   \n",
       "4  [{'text': 'HurricaneIan', 'indices': [195, 208...   \n",
       "\n",
       "                                                urls user_mentions  is_quote  \\\n",
       "0  [{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...            []     False   \n",
       "1  [{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...            []      True   \n",
       "2                                                 []            []     False   \n",
       "3  [{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...            []     False   \n",
       "4  [{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...            []      True   \n",
       "\n",
       "   is_retweet  text_blob                                               bert  \\\n",
       "0       False   0.000000  [{'label': 'Positive', 'score': 0.352827787399...   \n",
       "1       False   0.285714  [{'label': 'Neutral', 'score': 0.3550549745559...   \n",
       "2       False   0.625000  [{'label': 'Neutral', 'score': 0.4122076034545...   \n",
       "3       False   0.500000  [{'label': 'Positive', 'score': 0.351958453655...   \n",
       "4       False  -0.200000  [{'label': 'Neutral', 'score': 0.3944049477577...   \n",
       "\n",
       "   vader_compound bert_label  \n",
       "0         -0.1531   Positive  \n",
       "1          0.0000    Neutral  \n",
       "2          0.9134    Neutral  \n",
       "3         -0.3182   Positive  \n",
       "4          0.7579    Neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data \n",
    "\n",
    "df = pd.read_csv('data_sets/ready_for_analysis.csv')\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.931636Z",
     "start_time": "2022-11-17T07:09:08.921627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>replying_to</th>\n",
       "      <th>media</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>bert</th>\n",
       "      <th>vader_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“#Florida's death toll from #HurricaneIan tops...</td>\n",
       "      <td>AmPowerBlog</td>\n",
       "      <td>Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:43+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Florida', 'indices': [1, 9]}, {'tex...</td>\n",
       "      <td>[{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[{'label': 'Positive', 'score': 0.352827787399...</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republicans. can’t. be.  counted. on. to. do. ...</td>\n",
       "      <td>nivnos33</td>\n",
       "      <td>#RESISTER #Woke #Democrat #NeverGOP #VotingRig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:22+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'VoteOutEveryRepublican', 'indices':...</td>\n",
       "      <td>[{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[{'label': 'Neutral', 'score': 0.3550549745559...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leadership you can Trust. 🦟 Make sure to like ...</td>\n",
       "      <td>TrishTheCommish</td>\n",
       "      <td>#Commissioner, #Mom, #PublicServant, #Mosquito...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:09+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'text': 'leadbyexample', 'indices': [180, 19...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[{'label': 'Neutral', 'score': 0.4122076034545...</td>\n",
       "      <td>0.9134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Everyone,\\n1/3) Many Floridians face flo...</td>\n",
       "      <td>Find_and_Bind1</td>\n",
       "      <td>Amateur journalist, photographer, #bondage ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [112, 125...</td>\n",
       "      <td>[{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[{'label': 'Positive', 'score': 0.351958453655...</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lord, please be a refuge for those in need. Gi...</td>\n",
       "      <td>shellsfaith</td>\n",
       "      <td>My name is Shelly and this is where I will be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:45+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [195, 208...</td>\n",
       "      <td>[{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>[{'label': 'Neutral', 'score': 0.3944049477577...</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      screen_name  \\\n",
       "0  “#Florida's death toll from #HurricaneIan tops...      AmPowerBlog   \n",
       "1  Republicans. can’t. be.  counted. on. to. do. ...         nivnos33   \n",
       "2  Leadership you can Trust. 🦟 Make sure to like ...  TrishTheCommish   \n",
       "3  Hello Everyone,\\n1/3) Many Floridians face flo...   Find_and_Bind1   \n",
       "4  Lord, please be a refuge for those in need. Gi...      shellsfaith   \n",
       "\n",
       "                                    user_description  favourite_count  \\\n",
       "0  Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...                0   \n",
       "1  #RESISTER #Woke #Democrat #NeverGOP #VotingRig...                0   \n",
       "2  #Commissioner, #Mom, #PublicServant, #Mosquito...                2   \n",
       "3  Amateur journalist, photographer, #bondage ent...                0   \n",
       "4  My name is Shelly and this is where I will be ...                1   \n",
       "\n",
       "   retweet_count                 created_at replying_to  media  \\\n",
       "0              0  2022-10-03 20:19:43+00:00         NaN  False   \n",
       "1              0  2022-10-03 20:19:22+00:00         NaN  False   \n",
       "2              0  2022-10-03 20:19:09+00:00         NaN   True   \n",
       "3              0  2022-10-03 20:18:56+00:00         NaN  False   \n",
       "4              0  2022-10-03 20:18:45+00:00         NaN  False   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'Florida', 'indices': [1, 9]}, {'tex...   \n",
       "1  [{'text': 'VoteOutEveryRepublican', 'indices':...   \n",
       "2  [{'text': 'leadbyexample', 'indices': [180, 19...   \n",
       "3  [{'text': 'HurricaneIan', 'indices': [112, 125...   \n",
       "4  [{'text': 'HurricaneIan', 'indices': [195, 208...   \n",
       "\n",
       "                                                urls user_mentions  is_quote  \\\n",
       "0  [{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...            []     False   \n",
       "1  [{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...            []      True   \n",
       "2                                                 []            []     False   \n",
       "3  [{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...            []     False   \n",
       "4  [{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...            []      True   \n",
       "\n",
       "   is_retweet  text_blob                                               bert  \\\n",
       "0       False   0.000000  [{'label': 'Positive', 'score': 0.352827787399...   \n",
       "1       False   0.285714  [{'label': 'Neutral', 'score': 0.3550549745559...   \n",
       "2       False   0.625000  [{'label': 'Neutral', 'score': 0.4122076034545...   \n",
       "3       False   0.500000  [{'label': 'Positive', 'score': 0.351958453655...   \n",
       "4       False  -0.200000  [{'label': 'Neutral', 'score': 0.3944049477577...   \n",
       "\n",
       "   vader_compound  \n",
       "0         -0.1531  \n",
       "1          0.0000  \n",
       "2          0.9134  \n",
       "3         -0.3182  \n",
       "4          0.7579  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the 'bert_label' as I'll be bert's numeric score instead\n",
    "\n",
    "df = df.drop(columns = ['bert_label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:08.947542Z",
     "start_time": "2022-11-17T07:09:08.932777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>replying_to</th>\n",
       "      <th>media</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>bert_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“#Florida's death toll from #HurricaneIan tops...</td>\n",
       "      <td>AmPowerBlog</td>\n",
       "      <td>Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:43+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Florida', 'indices': [1, 9]}, {'tex...</td>\n",
       "      <td>[{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.352827787399292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republicans. can’t. be.  counted. on. to. do. ...</td>\n",
       "      <td>nivnos33</td>\n",
       "      <td>#RESISTER #Woke #Democrat #NeverGOP #VotingRig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:22+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'VoteOutEveryRepublican', 'indices':...</td>\n",
       "      <td>[{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.35505497455596924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leadership you can Trust. 🦟 Make sure to like ...</td>\n",
       "      <td>TrishTheCommish</td>\n",
       "      <td>#Commissioner, #Mom, #PublicServant, #Mosquito...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:09+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'text': 'leadbyexample', 'indices': [180, 19...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.41220760345458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Everyone,\\n1/3) Many Floridians face flo...</td>\n",
       "      <td>Find_and_Bind1</td>\n",
       "      <td>Amateur journalist, photographer, #bondage ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [112, 125...</td>\n",
       "      <td>[{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.3519584536552429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lord, please be a refuge for those in need. Gi...</td>\n",
       "      <td>shellsfaith</td>\n",
       "      <td>My name is Shelly and this is where I will be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:45+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [195, 208...</td>\n",
       "      <td>[{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.39440494775772095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      screen_name  \\\n",
       "0  “#Florida's death toll from #HurricaneIan tops...      AmPowerBlog   \n",
       "1  Republicans. can’t. be.  counted. on. to. do. ...         nivnos33   \n",
       "2  Leadership you can Trust. 🦟 Make sure to like ...  TrishTheCommish   \n",
       "3  Hello Everyone,\\n1/3) Many Floridians face flo...   Find_and_Bind1   \n",
       "4  Lord, please be a refuge for those in need. Gi...      shellsfaith   \n",
       "\n",
       "                                    user_description  favourite_count  \\\n",
       "0  Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...                0   \n",
       "1  #RESISTER #Woke #Democrat #NeverGOP #VotingRig...                0   \n",
       "2  #Commissioner, #Mom, #PublicServant, #Mosquito...                2   \n",
       "3  Amateur journalist, photographer, #bondage ent...                0   \n",
       "4  My name is Shelly and this is where I will be ...                1   \n",
       "\n",
       "   retweet_count                 created_at replying_to  media  \\\n",
       "0              0  2022-10-03 20:19:43+00:00         NaN  False   \n",
       "1              0  2022-10-03 20:19:22+00:00         NaN  False   \n",
       "2              0  2022-10-03 20:19:09+00:00         NaN   True   \n",
       "3              0  2022-10-03 20:18:56+00:00         NaN  False   \n",
       "4              0  2022-10-03 20:18:45+00:00         NaN  False   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'Florida', 'indices': [1, 9]}, {'tex...   \n",
       "1  [{'text': 'VoteOutEveryRepublican', 'indices':...   \n",
       "2  [{'text': 'leadbyexample', 'indices': [180, 19...   \n",
       "3  [{'text': 'HurricaneIan', 'indices': [112, 125...   \n",
       "4  [{'text': 'HurricaneIan', 'indices': [195, 208...   \n",
       "\n",
       "                                                urls user_mentions  is_quote  \\\n",
       "0  [{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...            []     False   \n",
       "1  [{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...            []      True   \n",
       "2                                                 []            []     False   \n",
       "3  [{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...            []     False   \n",
       "4  [{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...            []      True   \n",
       "\n",
       "   is_retweet  text_blob  vader_compound          bert_scores  \n",
       "0       False   0.000000         -0.1531    0.352827787399292  \n",
       "1       False   0.285714          0.0000  0.35505497455596924  \n",
       "2       False   0.625000          0.9134  0.41220760345458984  \n",
       "3       False   0.500000         -0.3182   0.3519584536552429  \n",
       "4       False  -0.200000          0.7579  0.39440494775772095  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the compound bert score into it's own seperate column and then removing\n",
    "# the bert column\n",
    "\n",
    "bert_scores = [x.split(' ')[3][:-2] for x in df['bert']]\n",
    "df['bert_scores'] = bert_scores\n",
    "df = df.drop(columns = 'bert')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.184793Z",
     "start_time": "2022-11-17T07:09:08.948435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_blob</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>bert_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.352827787399292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35505497455596924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.41220760345458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.3519584536552429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.39440494775772095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.39361315965652466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.38092079758644104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.3929575979709625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.6476</td>\n",
       "      <td>0.3635033667087555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.6239</td>\n",
       "      <td>0.4063631296157837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7652 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_blob vader_compound          bert_scores\n",
       "0            0        -0.1531    0.352827787399292\n",
       "1     0.285714              0  0.35505497455596924\n",
       "2        0.625         0.9134  0.41220760345458984\n",
       "3          0.5        -0.3182   0.3519584536552429\n",
       "4         -0.2         0.7579  0.39440494775772095\n",
       "...        ...            ...                  ...\n",
       "7647         0         0.3612  0.39361315965652466\n",
       "7648         0         0.8394  0.38092079758644104\n",
       "7649       0.8         0.8957   0.3929575979709625\n",
       "7650     0.125        -0.6476   0.3635033667087555\n",
       "7651      0.13        -0.6239   0.4063631296157837\n",
       "\n",
       "[7652 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a df just of the three different scores (which are all on seperate scales)\n",
    "\n",
    "voting_df =  [df['text_blob'], df['vader_compound'], df['bert_scores']]\n",
    "voting_df = pd.DataFrame(voting_df).transpose()\n",
    "voting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.197557Z",
     "start_time": "2022-11-17T07:09:09.185843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369372</td>\n",
       "      <td>-0.450888</td>\n",
       "      <td>-1.205824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.690463</td>\n",
       "      <td>-0.162506</td>\n",
       "      <td>-1.113238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.949018</td>\n",
       "      <td>1.557994</td>\n",
       "      <td>1.262663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.485340</td>\n",
       "      <td>-0.761874</td>\n",
       "      <td>-1.241964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.111258</td>\n",
       "      <td>1.265091</td>\n",
       "      <td>0.522586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>-0.369372</td>\n",
       "      <td>0.517858</td>\n",
       "      <td>0.489670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>-0.369372</td>\n",
       "      <td>1.418606</td>\n",
       "      <td>-0.037966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>2.598168</td>\n",
       "      <td>1.524654</td>\n",
       "      <td>0.462418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>0.094306</td>\n",
       "      <td>-1.382339</td>\n",
       "      <td>-0.762028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>0.112853</td>\n",
       "      <td>-1.337697</td>\n",
       "      <td>1.019701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7652 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0    -0.369372 -0.450888 -1.205824\n",
       "1     0.690463 -0.162506 -1.113238\n",
       "2     1.949018  1.557994  1.262663\n",
       "3     1.485340 -0.761874 -1.241964\n",
       "4    -1.111258  1.265091  0.522586\n",
       "...        ...       ...       ...\n",
       "7647 -0.369372  0.517858  0.489670\n",
       "7648 -0.369372  1.418606 -0.037966\n",
       "7649  2.598168  1.524654  0.462418\n",
       "7650  0.094306 -1.382339 -0.762028\n",
       "7651  0.112853 -1.337697  1.019701\n",
       "\n",
       "[7652 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instatiating StandardScaler and using it to transform the scoring df so all \n",
    "# three scores are on the same scale \n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "scaled_voting_df = pd.DataFrame(standard_scaler.fit_transform(voting_df))\n",
    "scaled_voting_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using a SUM based voting system which doesn't care if 2 voting columns agree with each other. In the future I'd like to experiment with making something a bit more sophisticated that would take into account if two voting columns agree on a certain range and a third is way off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.203897Z",
     "start_time": "2022-11-17T07:09:09.198533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369372</td>\n",
       "      <td>-0.450888</td>\n",
       "      <td>-1.205824</td>\n",
       "      <td>-2.026085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.690463</td>\n",
       "      <td>-0.162506</td>\n",
       "      <td>-1.113238</td>\n",
       "      <td>-0.585280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.949018</td>\n",
       "      <td>1.557994</td>\n",
       "      <td>1.262663</td>\n",
       "      <td>4.769675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.485340</td>\n",
       "      <td>-0.761874</td>\n",
       "      <td>-1.241964</td>\n",
       "      <td>-0.518498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.111258</td>\n",
       "      <td>1.265091</td>\n",
       "      <td>0.522586</td>\n",
       "      <td>0.676419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2  final_score\n",
       "0 -0.369372 -0.450888 -1.205824    -2.026085\n",
       "1  0.690463 -0.162506 -1.113238    -0.585280\n",
       "2  1.949018  1.557994  1.262663     4.769675\n",
       "3  1.485340 -0.761874 -1.241964    -0.518498\n",
       "4 -1.111258  1.265091  0.522586     0.676419"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding up the transformed scores into a final score that will be transformed \n",
    "# into labels\n",
    "\n",
    "scaled_voting_df['final_score'] = scaled_voting_df[0] + scaled_voting_df[1] + scaled_voting_df[2]\n",
    "scaled_voting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.382801Z",
     "start_time": "2022-11-17T07:09:09.205060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='final_score', ylabel='Count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# taking a look at the distribution of final scores, we can see a regular \n",
    "# distribution\n",
    "\n",
    "sns.histplot(scaled_voting_df['final_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.387416Z",
     "start_time": "2022-11-17T07:09:09.383891Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping text_blob, vader_compound and bert_score as we have our labels\n",
    "\n",
    "df = df.drop(columns=['text_blob', 'vader_compound', 'bert_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.396948Z",
     "start_time": "2022-11-17T07:09:09.388438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>replying_to</th>\n",
       "      <th>media</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“#Florida's death toll from #HurricaneIan tops...</td>\n",
       "      <td>AmPowerBlog</td>\n",
       "      <td>Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:43+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Florida', 'indices': [1, 9]}, {'tex...</td>\n",
       "      <td>[{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.026085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republicans. can’t. be.  counted. on. to. do. ...</td>\n",
       "      <td>nivnos33</td>\n",
       "      <td>#RESISTER #Woke #Democrat #NeverGOP #VotingRig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:22+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'VoteOutEveryRepublican', 'indices':...</td>\n",
       "      <td>[{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.585280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leadership you can Trust. 🦟 Make sure to like ...</td>\n",
       "      <td>TrishTheCommish</td>\n",
       "      <td>#Commissioner, #Mom, #PublicServant, #Mosquito...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:09+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'text': 'leadbyexample', 'indices': [180, 19...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.769675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Everyone,\\n1/3) Many Floridians face flo...</td>\n",
       "      <td>Find_and_Bind1</td>\n",
       "      <td>Amateur journalist, photographer, #bondage ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [112, 125...</td>\n",
       "      <td>[{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.518498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lord, please be a refuge for those in need. Gi...</td>\n",
       "      <td>shellsfaith</td>\n",
       "      <td>My name is Shelly and this is where I will be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:45+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [195, 208...</td>\n",
       "      <td>[{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      screen_name  \\\n",
       "0  “#Florida's death toll from #HurricaneIan tops...      AmPowerBlog   \n",
       "1  Republicans. can’t. be.  counted. on. to. do. ...         nivnos33   \n",
       "2  Leadership you can Trust. 🦟 Make sure to like ...  TrishTheCommish   \n",
       "3  Hello Everyone,\\n1/3) Many Floridians face flo...   Find_and_Bind1   \n",
       "4  Lord, please be a refuge for those in need. Gi...      shellsfaith   \n",
       "\n",
       "                                    user_description  favourite_count  \\\n",
       "0  Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...                0   \n",
       "1  #RESISTER #Woke #Democrat #NeverGOP #VotingRig...                0   \n",
       "2  #Commissioner, #Mom, #PublicServant, #Mosquito...                2   \n",
       "3  Amateur journalist, photographer, #bondage ent...                0   \n",
       "4  My name is Shelly and this is where I will be ...                1   \n",
       "\n",
       "   retweet_count                 created_at replying_to  media  \\\n",
       "0              0  2022-10-03 20:19:43+00:00         NaN  False   \n",
       "1              0  2022-10-03 20:19:22+00:00         NaN  False   \n",
       "2              0  2022-10-03 20:19:09+00:00         NaN   True   \n",
       "3              0  2022-10-03 20:18:56+00:00         NaN  False   \n",
       "4              0  2022-10-03 20:18:45+00:00         NaN  False   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'Florida', 'indices': [1, 9]}, {'tex...   \n",
       "1  [{'text': 'VoteOutEveryRepublican', 'indices':...   \n",
       "2  [{'text': 'leadbyexample', 'indices': [180, 19...   \n",
       "3  [{'text': 'HurricaneIan', 'indices': [112, 125...   \n",
       "4  [{'text': 'HurricaneIan', 'indices': [195, 208...   \n",
       "\n",
       "                                                urls user_mentions  is_quote  \\\n",
       "0  [{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...            []     False   \n",
       "1  [{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...            []      True   \n",
       "2                                                 []            []     False   \n",
       "3  [{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...            []     False   \n",
       "4  [{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...            []      True   \n",
       "\n",
       "   is_retweet  final_score  \n",
       "0       False    -2.026085  \n",
       "1       False    -0.585280  \n",
       "2       False     4.769675  \n",
       "3       False    -0.518498  \n",
       "4       False     0.676419  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['final_score'] = scaled_voting_df['final_score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.406562Z",
     "start_time": "2022-11-17T07:09:09.398286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7652 entries, 0 to 7651\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   text              7652 non-null   object \n",
      " 1   screen_name       7652 non-null   object \n",
      " 2   user_description  7364 non-null   object \n",
      " 3   favourite_count   7652 non-null   int64  \n",
      " 4   retweet_count     7652 non-null   int64  \n",
      " 5   created_at        7652 non-null   object \n",
      " 6   replying_to       1172 non-null   object \n",
      " 7   media             7652 non-null   bool   \n",
      " 8   hashtags          7652 non-null   object \n",
      " 9   urls              7652 non-null   object \n",
      " 10  user_mentions     7652 non-null   object \n",
      " 11  is_quote          7652 non-null   bool   \n",
      " 12  is_retweet        7652 non-null   bool   \n",
      " 13  final_score       7652 non-null   float64\n",
      "dtypes: bool(3), float64(1), int64(2), object(8)\n",
      "memory usage: 680.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.410277Z",
     "start_time": "2022-11-17T07:09:09.407701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7652, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.414595Z",
     "start_time": "2022-11-17T07:09:09.411475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-03 13:49:56+00:00'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_at'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started scraping at 10/03/2022 at 1:50 pm EST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.419002Z",
     "start_time": "2022-11-17T07:09:09.415805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-11 23:59:26+00:00'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_at'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:09.581390Z",
     "start_time": "2022-11-17T07:09:09.420301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dates = [x.split(' ')[0] for x in df['created_at']]\n",
    "\n",
    "sns.histplot(sorted(dates), bins = 7)\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T00:18:09.561895Z",
     "start_time": "2022-11-14T00:18:09.556417Z"
    }
   },
   "source": [
    "Stopped scraping at 10/11/2022 at 11:59 pm EST. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In future work, I want to really dig in and explore the correlations between sentiment and `favourite_count` or `retweet_count` and also explore all the features of this data. However, for the purposes of getting something deployed as fast as possible, with Hurricane Season on the way, I'm only going to be focusing on the text column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T22:40:46.401475Z",
     "start_time": "2022-11-10T22:40:46.398452Z"
    }
   },
   "source": [
    "### Removing Emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using clean_text to remove emojis from the text. After trying this \n",
    "process both with and without emojis and having the F1 scores come back in the same\n",
    "ranges, I've decided to remove the emojis, prioritizing making the text\n",
    "vectors less multidementional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:10.441942Z",
     "start_time": "2022-11-17T07:09:09.586343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"#florida\\'s death toll from #hurricaneian tops 100 as the search for survivors continues #fortmyers #ftmyers #ian https://t.co/rqcyahaxtk',\n",
       " \"republicans. can't. be. counted. on. to. do. the. right. thing.\\never.\\n#voteouteveryrepublican\\n#votethemallout\\n#hurricaneian https://t.co/me3qmrztsx\",\n",
       " 'leadership you can trust. make sure to like my commissioner trish becker anastasia mosquito control district page and share it with friends. vote by mail ballots went out today!\\n#leadbyexample #vote #politics #hurricanian #hurricaneian #hurricane #staugustine #women #mosquito https://t.co/mhs9wz1bsc',\n",
       " 'hello everyone,\\n1/3) many floridians face flood damage from ian without flood insurance\\nhttps://t.co/lgo1y1sfsk\\n#hurricaneian #florida #flooddamage #insurance #fema #grants',\n",
       " 'lord, please be a refuge for those in need. give them the comfort of your presence. bring them peace and give them strength to carry on in the midst of trouble and loss. in your holy name, amen.\\n#hurricaneian #hurricane #prayforflorida #prayer https://t.co/m4c6nh2x1u',\n",
       " \"over 90% of fort myers beach, a town in south west florida, is destroyed following deadly hurricane ian. our crew is there talking to residents and survivors. here are some of the pictures we've captured.\\n#ftmyersbeach #hurricaneian #fortmyers https://t.co/hip2qrilmp\",\n",
       " 'continuing to bring you updates on the aftermath of #hurricaneian\\n#hurricane #ian #fl #florida #news #onscene #update #fortmyersbeach https://t.co/1im4sflezk',\n",
       " \"@dwuhlfelderlaw @sarahburris @acosta soooo, let me get this straight. the very same ppl who say there's zero chance fraud is ever committed in an election are now saying @govrondesantis is literally hiding hundreds of dead bodies after #hurricaneian.\\nwill the real conspiracy theorists please stand up. gtfo!\",\n",
       " 'west africa really did send its best #hurricaneian https://t.co/ujwoqllapk',\n",
       " 'you would think someone \"so involved with the fishing community\" would be finding out ways to help it #fishing #hurricaneian #florida']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a list of all tweets without emojis\n",
    "\n",
    "no_emojis = [clean(x, no_emoji = True) for x in df['text']]\n",
    "no_emojis[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:10.452461Z",
     "start_time": "2022-11-17T07:09:10.444492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>replying_to</th>\n",
       "      <th>media</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>final_score</th>\n",
       "      <th>no_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“#Florida's death toll from #HurricaneIan tops...</td>\n",
       "      <td>AmPowerBlog</td>\n",
       "      <td>Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:43+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'Florida', 'indices': [1, 9]}, {'tex...</td>\n",
       "      <td>[{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.026085</td>\n",
       "      <td>\"#florida's death toll from #hurricaneian tops...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republicans. can’t. be.  counted. on. to. do. ...</td>\n",
       "      <td>nivnos33</td>\n",
       "      <td>#RESISTER #Woke #Democrat #NeverGOP #VotingRig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:22+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'VoteOutEveryRepublican', 'indices':...</td>\n",
       "      <td>[{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.585280</td>\n",
       "      <td>republicans. can't. be. counted. on. to. do. t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leadership you can Trust. 🦟 Make sure to like ...</td>\n",
       "      <td>TrishTheCommish</td>\n",
       "      <td>#Commissioner, #Mom, #PublicServant, #Mosquito...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:19:09+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'text': 'leadbyexample', 'indices': [180, 19...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.769675</td>\n",
       "      <td>leadership you can trust. make sure to like my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Everyone,\\n1/3) Many Floridians face flo...</td>\n",
       "      <td>Find_and_Bind1</td>\n",
       "      <td>Amateur journalist, photographer, #bondage ent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [112, 125...</td>\n",
       "      <td>[{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.518498</td>\n",
       "      <td>hello everyone,\\n1/3) many floridians face flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lord, please be a refuge for those in need. Gi...</td>\n",
       "      <td>shellsfaith</td>\n",
       "      <td>My name is Shelly and this is where I will be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-03 20:18:45+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'text': 'HurricaneIan', 'indices': [195, 208...</td>\n",
       "      <td>[{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676419</td>\n",
       "      <td>lord, please be a refuge for those in need. gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      screen_name  \\\n",
       "0  “#Florida's death toll from #HurricaneIan tops...      AmPowerBlog   \n",
       "1  Republicans. can’t. be.  counted. on. to. do. ...         nivnos33   \n",
       "2  Leadership you can Trust. 🦟 Make sure to like ...  TrishTheCommish   \n",
       "3  Hello Everyone,\\n1/3) Many Floridians face flo...   Find_and_Bind1   \n",
       "4  Lord, please be a refuge for those in need. Gi...      shellsfaith   \n",
       "\n",
       "                                    user_description  favourite_count  \\\n",
       "0  Sports Twitter is the best Twitter. 🏈🏇🎾🛹⚾🏌️😎🚴🏐...                0   \n",
       "1  #RESISTER #Woke #Democrat #NeverGOP #VotingRig...                0   \n",
       "2  #Commissioner, #Mom, #PublicServant, #Mosquito...                2   \n",
       "3  Amateur journalist, photographer, #bondage ent...                0   \n",
       "4  My name is Shelly and this is where I will be ...                1   \n",
       "\n",
       "   retweet_count                 created_at replying_to  media  \\\n",
       "0              0  2022-10-03 20:19:43+00:00         NaN  False   \n",
       "1              0  2022-10-03 20:19:22+00:00         NaN  False   \n",
       "2              0  2022-10-03 20:19:09+00:00         NaN   True   \n",
       "3              0  2022-10-03 20:18:56+00:00         NaN  False   \n",
       "4              0  2022-10-03 20:18:45+00:00         NaN  False   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'Florida', 'indices': [1, 9]}, {'tex...   \n",
       "1  [{'text': 'VoteOutEveryRepublican', 'indices':...   \n",
       "2  [{'text': 'leadbyexample', 'indices': [180, 19...   \n",
       "3  [{'text': 'HurricaneIan', 'indices': [112, 125...   \n",
       "4  [{'text': 'HurricaneIan', 'indices': [195, 208...   \n",
       "\n",
       "                                                urls user_mentions  is_quote  \\\n",
       "0  [{'url': 'https://t.co/RqcyAHAxtk', 'expanded_...            []     False   \n",
       "1  [{'url': 'https://t.co/Me3qmrzTsX', 'expanded_...            []      True   \n",
       "2                                                 []            []     False   \n",
       "3  [{'url': 'https://t.co/lgO1y1sFsK', 'expanded_...            []     False   \n",
       "4  [{'url': 'https://t.co/M4c6nH2x1U', 'expanded_...            []      True   \n",
       "\n",
       "   is_retweet  final_score                                          no_emojis  \n",
       "0       False    -2.026085  \"#florida's death toll from #hurricaneian tops...  \n",
       "1       False    -0.585280  republicans. can't. be. counted. on. to. do. t...  \n",
       "2       False     4.769675  leadership you can trust. make sure to like my...  \n",
       "3       False    -0.518498  hello everyone,\\n1/3) many floridians face flo...  \n",
       "4       False     0.676419  lord, please be a refuge for those in need. gi...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making no_emojis list into into a column, I'll be doing all my text processing \n",
    "# on this new column\n",
    "\n",
    "df['no_emojis'] = no_emojis\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords, Numbers, URLS, Punctuation and Lemmatizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using a combination of NLTK and spaCy along with some other smaller text libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:11.079994Z",
     "start_time": "2022-11-17T07:09:10.453853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anyone', 'here', 'thus', '1', 'no', '{', '`', '\\n', '#', \"'re\", 'anyway', 'due', 'against', 'except', 'those', 'thereby', 'many', '~', 'whatever', 'someone', 'be', 'beforehand', 'out', 'indeed', 'go', 'namely', 'above', 'whose', 'too', 'somehow', \"'ve\", '=', 'most', 'sometimes', 'thereafter', 'there', 'his', 'upon', 're', 'meanwhile', '%', 'not', 'fifteen', 'hence', ')', 'almost', 'seems', 'n‘t', 'we', 'same', 'my', 'because', 'down', 'its', 'really', ']', 'th', 'through', 'nine', 'onto', 'across', 'been', 'another', '>', 'a', 'empty', 'others', 'now', 'used', 'elsewhere', '^', 'somewhere', 'more', 'ourselves', 'wherever', 'hereby', 'her', 'just', 'among', 'whereby', 'below', '3', 'else', '|', 'done', 'towards', 'least', '0', 'whereupon', 'together', 'every', 'again', 'please', 'afterwards', 'something', 'you', 'top', 'several', 'nowhere', 'herein', '_', 'n’t', 'until', 'anyhow', 'own', 'amongst', 'eleven', 'they', 'some', 'put', 'them', 'ever', 'serious', 'bottom', 'seeming', 'show', 'anything', 'since', 'hereupon', '’re', 'whom', 'seemed', 'therefore', 'from', 'for', 'other', 'take', '<', '}', '&', 'ian', 'around', '‘m', 'whereafter', 'which', 'an', 'us', 'even', 'hurricane', 'see', 'whereas', '\"', 'all', 'eight', 'am', 'has', 'must', 'keep', 'have', 'few', 'yourself', 'beyond', 'next', \"'ll\", 'does', 'hundred', 'yours', \"n't\", \"'\", 'mine', 'myself', '‘d', '6', 'beside', 'get', 'of', \"'d\", 'part', 'are', 'our', 'make', 'already', '’ve', '’d', 'their', 'these', 'why', 'full', 'third', 'wherein', 'but', \"'m\", 'off', 'the', 'nor', 'everyone', 'such', 'into', 'whoever', 'however', 'latter', 'becomes', '‘re', 'who', 'what', ':', '+', 'also', 'florida', 'in', '[', 'should', 'hers', 's', 'becoming', 'after', 'latterly', 'back', 'fifty', '‘ll', 'everywhere', 'anywhere', 'six', 'five', 'yet', 'thence', 'via', 'still', '7', 'could', 'can', 'though', 'this', 'each', 'regarding', 'formerly', 'any', 'ours', 'themselves', 'whenever', 'amp', 'perhaps', 'whence', 'first', 'hereafter', 'will', 'very', 'three', 'using', 'whether', 'with', 'did', 'twenty', 'along', 'so', 'nevertheless', 'sixty', 'up', 'call', 'between', '/', '!', 'often', '‘ve', 'then', 'once', 'hurricaneian', '?', 'various', '@', 'seem', \"'s\", 'how', '9', 'become', 'although', 'within', '$', 'became', 'well', 'thereupon', 'himself', 'being', 'both', 'was', 'four', 'as', 'him', 'without', 'noone', 'if', 'everything', 'former', '5', 'per', 'at', 'is', 'where', 'nobody', 'she', 'by', '(', 'doing', 'over', 'front', 'were', 'nothing', 'might', ';', 'say', 'cannot', 'to', 'do', 'rather', '-', 'one', 'otherwise', '‘s', 'i', 'behind', 'he', 'mostly', 'last', 'further', 'whole', 'thru', 'or', 'herself', 'always', 'either', 'may', 'besides', 'twelve', 'and', 'before', 'much', '\\\\', 'only', 'it', 'throughout', 'name', '8', 'would', 'neither', 'made', 'on', 'that', 'unless', 'none', 'your', 'whither', 'ca', '.', 'during', 'quite', 'less', 'under', 'when', 'had', 'toward', 'never', 'about', 'ten', 'side', 'amount', 'me', 'than', 'move', 'while', '’s', '’m', '’ll', 'yourselves', 'forty', 'moreover', 'alone', '*', 'itself', '\\n\\n', ',', 'enough', '2', 'give', 'sometime', 'two', '4', 'therein'}\n"
     ]
    }
   ],
   "source": [
    "# instantiating nlp and stopwords, adding some twitter specific and case \n",
    "# specific stopwords, as well as adding all digets and punctuation to stopwords\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "stopwords_to_add = [\"\\n\", \"\\n\\n\", \"hurricaneian\", \"ian\", \"hurricane\", \n",
    "                    \"florida\", \"s\", \"amp\", \"th\"]\n",
    "\n",
    "for x in stopwords_to_add:\n",
    "    stopwords.add(x)\n",
    "\n",
    "for x in string.punctuation:\n",
    "    stopwords.add(x)\n",
    "    \n",
    "for x in string.digits:\n",
    "    stopwords.add(x)\n",
    "\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block is a bit hairy and I'd like to come back to it to make it\n",
    "more organized and less nested for better performance. It does the following:\n",
    "\n",
    "1) makes an empty list for doc tokens\n",
    "\n",
    "2) for each row in the no_emojis column\n",
    "\n",
    "3) make an empty list of all tokens in the tweet\n",
    "\n",
    "4) \"fix\" the contractions in the tweet to keep meaning and remove punctuation ie \"haven't\" turns to \"have not\" and assign that string as \"new_text\"\n",
    "\n",
    "5) make \"new text\" into a spaCy NLP doc\n",
    "\n",
    "6) for each token in the spaCy NLP doc: if the token isn't in spaCy's punctuation AND if it's lemma_ (rootword) isn't a pronoun, and the token is neither a a spaCy number or a url: add token's lemma_ (rootword) to list 'tokens_in_text' after making it lower case and stripping it of surrounding spaces\n",
    "\n",
    "7) for each token in 'tokens_in_text', filter out string.punctuation (filters more than just spaCy's punctuation) \n",
    "\n",
    "8) for each token in 'tokens_in_text', filter out string.digits (filters more than just spaCy's 'like_numb')\n",
    "\n",
    "9) for teach token in 'tokens_in_text', filter out all stopwords (which should include both string.punctuation and string.digits, but after running this code block a few different ways, I find added filtration with all these steps.) \n",
    "\n",
    "10) make an object of a blank and remove all blank tokens from 'tokens_in_text'\n",
    "\n",
    "11) adds final 'tokens_in_text' list to list of doc_tokens\n",
    "\n",
    "12) list of doc_tokens becomes a new column in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:11.082645Z",
     "start_time": "2022-11-17T07:09:11.080935Z"
    }
   },
   "outputs": [],
   "source": [
    "contractions.add('Ft', 'Fort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.341294Z",
     "start_time": "2022-11-17T07:09:11.083398Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f6cd361e6137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokens_in_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnew_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_punct\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'-PRON-'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlike_num\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(seqs_in)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/thinc/check.py\u001b[0m in \u001b[0;36mchecked_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mExpectedTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Callable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0marg_check_adder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/thinc/neural/_classes/softmax.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input__BI)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput__BO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__BO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput__BO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mops.pyx\u001b[0m in \u001b[0;36mthinc.neural.ops.Ops.softmax\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0m\u001b[1;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# remove all punctuation, numbers, stopwords \n",
    "# get lowercased lemma (rootword) from token\n",
    "# make list of lemmas into new column in df\n",
    "\n",
    "list_of_doc_tokens = []\n",
    "for text in df['no_emojis']:\n",
    "    tokens_in_text = []\n",
    "    new_text = contractions.fix(text)\n",
    "    doc = nlp(new_text)\n",
    "    for token in doc:\n",
    "        if not token.is_punct and token.lemma_ != '-PRON-' and not token.like_num\\\n",
    "        and not token.like_url:\n",
    "            tokens_in_text.append(token.lemma_.lower().strip())\n",
    "\n",
    "    tokens_in_text = [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens_in_text]\n",
    "    tokens_in_text = [token.translate(str.maketrans('', '', string.digits)) for token in tokens_in_text]\n",
    "    tokens_in_text = [token for token in tokens_in_text if token not in set(stopwords)]\n",
    "    \n",
    "    blank = ''\n",
    "    tokens_in_text = [token for token in tokens_in_text if token is not blank]\n",
    "    list_of_doc_tokens.append(tokens_in_text)\n",
    "\n",
    "df['tokens'] = list_of_doc_tokens\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Spammers\n",
    "\n",
    "A bunch of tweets are bot tweets that post the same message with different links. Therefore now that the URLS are removed, I'll be checking once more for duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.344101Z",
     "start_time": "2022-11-17T07:09:06.723Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['no_emojis', 'screen_name'])\n",
    "df.shape\n",
    "\n",
    "# this appears to have only gotten rid of 3 tweets. Instead I will explore\n",
    "# how many of the rows are from the same users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.344881Z",
     "start_time": "2022-11-17T07:09:06.724Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "users = [x for x in df['screen_name']]\n",
    "\n",
    "counter_ = (Counter(users))\n",
    "\n",
    "counter_ = dict(sorted(counter_.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "\n",
    "top_20_spammers = dict(itertools.islice(counter_.items(), 20)) \n",
    "print(top_20_spammers)\n",
    "top_20_spammers = [key for key in top_20_spammers.keys()]\n",
    "top_20_spammers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future I'd like to sample the data by only grabbing one tweet for username\n",
    "or at least a way to keep the first tweets by each of the spammers but for right now I'm just going to remove those rows from these users. \n",
    "\n",
    "BIAS: I am introducing bias into this data set here. Someone can be in distress and therefore tweeting about it frequently. Since I'll be making a lot of changes to data collection and training in the future anyway, I'm going to accept this bias as is for now and keep going. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.345439Z",
     "start_time": "2022-11-17T07:09:06.726Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[~df['screen_name'].isin(top_20_spammers)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.345996Z",
     "start_time": "2022-11-17T07:09:06.727Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.346536Z",
     "start_time": "2022-11-17T07:09:06.728Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df['final_score'] = scaled_voting_df['final_score']\n",
    "sentiment_df = df.sort_values(by = 'final_score')\n",
    "for x in sentiment_df.head().values:\n",
    "    print(f'TEXT: {x[0]}\\n\\nSCORE: {x[13]}\\n \\\n",
    "______________________________________________________________________________\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: All the most negative tweets involve political figures except the last. That's very interesting especially since we can see that they don't agree. In the future I'll want to make tweets only like the last tweet included in the target. Right now, I'm going to use the data as is as a proof of concept until I get a chance to make better labels and filter out sales tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.347190Z",
     "start_time": "2022-11-17T07:09:06.730Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in sentiment_df.tail().values:\n",
    "    print(f'TEXT: {x[0]}\\n\\nSCORE: {x[13]}\\n \\\n",
    "______________________________________________________________________________\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: I'll want to go back and do more careful cleaning in the future so that the above three 'lifestyle content' posts and ones like it don't muddy the waters of the data, which appear to have gotten through my filters by posting new URLs and slightly different messages for each tweet, so they aren't recognized as duplicates. In the future, I'll need better filters to remove sales tweets. For the time being, I'm going to carry on since this won't effect the Negative Sentiment Class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to classify any final score over 0 to be in the positive sentiment\n",
    " class and any final scores that were below 0 into the negative class. The negative class will be the target class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.347844Z",
     "start_time": "2022-11-17T07:09:06.732Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making an empty list of labels, using a for loop to make my labels and making \n",
    "# that list into a column \n",
    "labels = []\n",
    "\n",
    "for x in df['final_score']:\n",
    "    if x > 0:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "df['labels'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.348438Z",
     "start_time": "2022-11-17T07:09:06.733Z"
    }
   },
   "outputs": [],
   "source": [
    "# looking at the distribution of classes, we have a pretty balenced data set\n",
    "\n",
    "df['labels'].value_counts(normalize = True) \n",
    "# Classes for the target are balenced roughly, the difference is off by about 5% which is negligable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on Negative and Positive Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.349002Z",
     "start_time": "2022-11-17T07:09:06.735Z"
    }
   },
   "outputs": [],
   "source": [
    "# seperating out the negative sentiment tweets and positive sentiment tweets \n",
    "# into two seperate dfs \n",
    "\n",
    "neg_df = df.loc[df['labels'] == 0]\n",
    "pos_df = df.loc[df['labels'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.349783Z",
     "start_time": "2022-11-17T07:09:06.736Z"
    }
   },
   "outputs": [],
   "source": [
    "# increasing the default number of max_length so I can make sure I can proceed\n",
    "\n",
    "nlp.max_length = 1200000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.350483Z",
     "start_time": "2022-11-17T07:09:06.738Z"
    }
   },
   "outputs": [],
   "source": [
    "# making a string of all the tokens in the negative df and running that string \n",
    "# through the most_common function \n",
    "\n",
    "neg_doc_string = \" \".join([item for sublist in neg_df['tokens'] for item in sublist])\n",
    "common_neg = most_common(neg_doc_string, \"Negative Sentiment Tweets\")[1]\n",
    "common_neg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.350982Z",
     "start_time": "2022-11-17T07:09:06.739Z"
    }
   },
   "outputs": [],
   "source": [
    "# making a string of all the tokens in the postive df and running that string \n",
    "# through the most_common function \n",
    "\n",
    "pos_doc_string = \" \".join([item for sublist in pos_df['tokens'] for item in sublist])\n",
    "common_posi = most_common(pos_doc_string, \"Positive Sentiment Tweets\")[1]\n",
    "common_posi;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.351526Z",
     "start_time": "2022-11-17T07:09:06.741Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_tokens = [token for sublist in neg_df['tokens'] for token in sublist]\n",
    "\n",
    "bigrams(neg_tokens, \"Negative Sentiment\", 'negative_bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.352154Z",
     "start_time": "2022-11-17T07:09:06.742Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_tokens = [token for sublist in pos_df['tokens'] for token in sublist]\n",
    "\n",
    "bigrams(pos_tokens, \"Positive Sentiment\", 'positive_bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.352809Z",
     "start_time": "2022-11-17T07:09:06.743Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_word_cloud = make_word_cloud(neg_doc_string, 'neg_word_cloud')\n",
    "neg_word_cloud;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.353327Z",
     "start_time": "2022-11-17T07:09:06.745Z"
    }
   },
   "outputs": [],
   "source": [
    "posi_word_cloud = make_word_cloud(pos_doc_string, 'posi_word_cloud')\n",
    "posi_word_cloud;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Method\n",
    "I'll be using Random Forest, XGBoost, NaiveBayes and CatBooost to try and classify tweets into either positive or negative sentiment and then checking the labels against those predictions. For each algorithm, I'll be trying both a TFIDF vectorizer and a more simplistic CountVectorizer. I'll proceed with the algorithm and vector combination with the best F1 score relative to it's computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be splitting the data into 80% training data, 10% test data and 10% validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.353882Z",
     "start_time": "2022-11-17T07:09:06.748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.354568Z",
     "start_time": "2022-11-17T07:09:06.749Z"
    }
   },
   "outputs": [],
   "source": [
    "token_strings = []\n",
    "for x in df['tokens']:\n",
    "    string = \" \".join(x)\n",
    "    token_strings.append(string)\n",
    "    \n",
    "df['tokens'] = token_strings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.355174Z",
     "start_time": "2022-11-17T07:09:06.750Z"
    }
   },
   "outputs": [],
   "source": [
    "# for the modeling purposes, I'll only be using the 'tokens' column and 'labels' column\n",
    "X = df['tokens']\n",
    "y = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.355739Z",
     "start_time": "2022-11-17T07:09:06.752Z"
    }
   },
   "outputs": [],
   "source": [
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.356327Z",
     "start_time": "2022-11-17T07:09:06.753Z"
    }
   },
   "outputs": [],
   "source": [
    "# To Do: make a TFIDF function and a Count Vectorizer function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.356869Z",
     "start_time": "2022-11-17T07:09:06.754Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train_tfidf_vec = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf_vec = tfidf_vectorizer.transform(X_test)\n",
    "X_valid_tfidf_vec = tfidf_vectorizer.transform(X_valid)\n",
    "X_train_tfidf_vec_df = pd.DataFrame(X_train_tfidf_vec.toarray())\n",
    "X_valid_tfidf_vec_df = pd.DataFrame(X_valid_tfidf_vec.toarray())\n",
    "X_train_tfidf_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.357457Z",
     "start_time": "2022-11-17T07:09:06.756Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "count_vectorizer.fit(X_train)\n",
    "X_train_cv_vec = count_vectorizer.transform(X_train)\n",
    "X_test_cv_vec = count_vectorizer.transform(X_test)\n",
    "X_valid_cv_vec = count_vectorizer.transform(X_valid)\n",
    "X_train_cv_vec_df = pd.DataFrame(X_train_cv_vec.toarray())\n",
    "X_valid_cv_vec_df = pd.DataFrame(X_valid_cv_vec.toarray())\n",
    "X_train_cv_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.358059Z",
     "start_time": "2022-11-17T07:09:06.757Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_tfidf_vec.shape)\n",
    "print(X_test_tfidf_vec.shape)\n",
    "print(X_valid_tfidf_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.358857Z",
     "start_time": "2022-11-17T07:09:06.758Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_cv_vec.shape)\n",
    "print(X_test_cv_vec.shape)\n",
    "print(X_valid_cv_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.360195Z",
     "start_time": "2022-11-17T07:09:06.760Z"
    }
   },
   "outputs": [],
   "source": [
    "# making a GridsearchCV grid for a Random Forest Machine\n",
    "\n",
    "rf_gscv_params = {\n",
    "    'min_samples_split': [2, 3, 4, 5, 6],\n",
    "    'min_samples_leaf' : [1, 2, 3, 4, 5, 6],\n",
    "    'max_features' : ['sqrt'],\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'class_weight': ['balanced']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.361863Z",
     "start_time": "2022-11-17T07:09:06.762Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiating the random forest classifyer\n",
    "rf_clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#Applying classifyer and grid for the Gridsearch\n",
    "rf_gs_tfidf = GridSearchCV(estimator = rf_clf, param_grid = rf_gscv_params, \n",
    "                           scoring = 'f1', cv = 5)\n",
    "\n",
    "#Fitting model with the training data\n",
    "rf_gs_tfidf.fit(X_train_tfidf_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.372183Z",
     "start_time": "2022-11-17T07:09:06.763Z"
    }
   },
   "outputs": [],
   "source": [
    "# investigating the best params\n",
    "rf_gs_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.372781Z",
     "start_time": "2022-11-17T07:09:06.764Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting my predictions from the best TFIDF random forest classyfier and evaluating\n",
    "# those predictions \n",
    "\n",
    "y_preds = rf_gs_tfidf.predict(X_train_tfidf_vec)\n",
    "\n",
    "evaluate(rf_gs_tfidf, X_train_tfidf_vec, y_train, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this Random Forest Classyfier was able to account for 98% of the variance in the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.373500Z",
     "start_time": "2022-11-17T07:09:06.766Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting the predictions of this best random forest classyfier and trying those predictions \n",
    "# against the test labels for evaluation \n",
    "\n",
    "y_preds = rf_gs_tfidf.predict(X_test_tfidf_vec)\n",
    "\n",
    "evaluate(rf_gs_tfidf, X_test_tfidf_vec, y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a 10% drop in the ability of this random forest algorithm's ability to explain the variance and our F1 score dropped by about 10% on data the model had never seen before. This is a healthy drop and not concerning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.374077Z",
     "start_time": "2022-11-17T07:09:06.768Z"
    }
   },
   "outputs": [],
   "source": [
    "#Applying classyfier and grid for the Gridsearch\n",
    "rf_gs_cv = GridSearchCV(estimator = rf_clf, param_grid = rf_gscv_params, scoring = 'f1', cv = 5)\n",
    "\n",
    "#Fitting model with the training data\n",
    "rf_gs_cv.fit(X_train_cv_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.374830Z",
     "start_time": "2022-11-17T07:09:06.769Z"
    }
   },
   "outputs": [],
   "source": [
    "# investigating best params\n",
    "\n",
    "rf_gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.375439Z",
     "start_time": "2022-11-17T07:09:06.771Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting predictions to try against the training labels for evaluation\n",
    "\n",
    "y_preds = rf_gs_cv.predict(X_train_cv_vec)\n",
    "\n",
    "evaluate(rf_gs_cv, X_train_cv_vec, y_train, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this algorithm can explain 100% of the variance in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.376155Z",
     "start_time": "2022-11-17T07:09:06.772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting predictions for this random forest on test data for evaluation\n",
    "\n",
    "y_preds = rf_gs_cv.predict(X_test_cv_vec)\n",
    "\n",
    "evaluate(rf_gs_cv, X_test_cv_vec, y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model also had a 10% drop in it's ability to explain the variance in the data, and our F1 score had another 10% healthy drop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG BOOST Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.376852Z",
     "start_time": "2022-11-17T07:09:06.774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Counter to do calculations for the weights for the model, \n",
    "# while this data is relatively balenced, this can't hurt\n",
    "from collections import Counter\n",
    "counter = Counter(y)\n",
    "# estimate scale_pos_weight value\n",
    "estimate = counter[0] / counter[1]\n",
    "print('Estimate: %.3f' % estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.377511Z",
     "start_time": "2022-11-17T07:09:06.776Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting of parameters for gridsearch to use\n",
    "xgb_grid = {\n",
    "    'learning_rate': [0.1, 0.3, 0.5, 0.7],\n",
    "    'max_depth': [10, 11, 12, 13, 14],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'subsample': [0.3, 0.5, 0.7],\n",
    "    'n_estimators': [20, 25, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.378168Z",
     "start_time": "2022-11-17T07:09:06.777Z"
    }
   },
   "outputs": [],
   "source": [
    "# instatiating the xgb classifyer\n",
    "xg_clf = XGBClassifier()\n",
    "\n",
    "#Applying classifyer and grid for the Gridsearch\n",
    "xg_gs_tfidf = GridSearchCV(estimator = xg_clf, param_grid = xgb_grid, scoring = 'f1', cv = 5)\n",
    "\n",
    "#Fitting model with the training data\n",
    "xg_gs_tfidf.fit(X_train_tfidf_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.378714Z",
     "start_time": "2022-11-17T07:09:06.778Z"
    }
   },
   "outputs": [],
   "source": [
    "# investigating the best params\n",
    "\n",
    "xg_gs_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.379229Z",
     "start_time": "2022-11-17T07:09:06.780Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting predictions to try against the training labels\n",
    "\n",
    "y_preds = xg_gs_tfidf.predict(X_train_tfidf_vec)\n",
    "evaluate(xg_gs_tfidf, X_train_tfidf_vec, y_train, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the XGBoost algothim on TFIDF data was able to explain about 96% of the variance, \n",
    "but the F1 score is down from that AUC score by about 7%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.379742Z",
     "start_time": "2022-11-17T07:09:06.782Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting predictions for XBGoost classyfier on TFIDF test data to try against \n",
    "# the labels for evaluation\n",
    "\n",
    "y_preds = xg_gs_tfidf.predict(X_test_tfidf_vec)\n",
    "evaluate(xg_gs_tfidf, X_test_tfidf_vec, y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model on the TFIDF training data could explain about 85% of the variance, down 10% from the training data. Likewise, this model's F1 score is down from 89% to about 78% in a healthy drop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.380263Z",
     "start_time": "2022-11-17T07:09:06.784Z"
    }
   },
   "outputs": [],
   "source": [
    "#Applying classyfier and grid for the Gridsearch\n",
    "xg_gs_cv = GridSearchCV(estimator = xg_clf, param_grid = xgb_grid, scoring = 'f1', cv = 5)\n",
    "\n",
    "#Fitting model with the training data\n",
    "xg_gs_cv.fit(X_train_cv_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.380817Z",
     "start_time": "2022-11-17T07:09:06.785Z"
    }
   },
   "outputs": [],
   "source": [
    "# investigating the best params \n",
    "xg_gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.381438Z",
     "start_time": "2022-11-17T07:09:06.786Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting y predictions for classyfier to try against training lables for evaluation\n",
    "\n",
    "y_preds = xg_gs_cv.predict(X_train_cv_vec)\n",
    "evaluate(xg_gs_cv, X_train_cv_vec, y_train, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model can expalin about the same amount of Variance in the training data when working on Count Vectorized data, likewise the F1 score is about the same, both only loosing about 1%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.382031Z",
     "start_time": "2022-11-17T07:09:06.788Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting predictions for this classyfier on test data to try aginst labels for \n",
    "# Evaluation \n",
    "\n",
    "y_preds = xg_gs_cv.predict(X_test_cv_vec)\n",
    "evaluate(xg_gs_cv, X_test_cv_vec, y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the same healthy drop of about 10% in the AUC and F1 score for this model as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.382506Z",
     "start_time": "2022-11-17T07:09:06.790Z"
    }
   },
   "outputs": [],
   "source": [
    "# for the multinomail naive bayes algorithm I will not be trying GridSearch, \n",
    "# but instead be using the out-of-the-box Multinomial Naive Bayes algothim\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "#Fitting model with the training data\n",
    "nb_clf.fit(X_train_tfidf_vec.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I didn't gridsearch this alorthim, training the algorithm is extreamly quick compared to the other algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.383101Z",
     "start_time": "2022-11-17T07:09:06.792Z"
    }
   },
   "outputs": [],
   "source": [
    "# investigating the default params\n",
    "\n",
    "nb_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.383648Z",
     "start_time": "2022-11-17T07:09:06.793Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting predictions for the Naive Bayes machine to try against the TFIDF training data\n",
    "# for evaluation\n",
    "\n",
    "# the Naive Bayes algorthim expects an array, not a sparse DF, hense the .toarray()\n",
    "\n",
    "y_preds = nb_clf.predict(X_train_tfidf_vec.toarray())\n",
    "evaluate(nb_clf, X_train_tfidf_vec.toarray(), y_train, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Naive Bayes algorithm was able to account for about 96% of the variance with only a 5% drop from there in F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.384235Z",
     "start_time": "2022-11-17T07:09:06.795Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting the predictions the classyfier made to try against the test labels\n",
    "# for evaluation \n",
    "\n",
    "y_preds = nb_clf.predict(X_test_tfidf_vec.toarray())\n",
    "evaluate(nb_clf, X_test_tfidf_vec.toarray(), y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test data, the algorthim was able to explain 88% of the variance and the F1 score is about 80%, which is similar to other, much harder to train algorithms. Naive Bayes' positive advantages aren't in the F1 score or AUC score but in it's lightweight nature and quickness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.384881Z",
     "start_time": "2022-11-17T07:09:06.797Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fitting model with the training data\n",
    "nb_clf.fit(X_train_cv_vec.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.385437Z",
     "start_time": "2022-11-17T07:09:06.799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting predictions of algorithm on training data to test against labels for evaluation \n",
    "\n",
    "y_preds = nb_clf.predict(X_train_cv_vec.toarray())\n",
    "evaluate(nb_clf, X_train_cv_vec.toarray(), y_train, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifyer on CountVectorized training data was able to explain 96% of the variance, with the F1 score dropped about 6% from the AUC score at 90%, similar to the TFIDF metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.385974Z",
     "start_time": "2022-11-17T07:09:06.801Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_preds = nb_clf.predict(X_test_cv_vec.toarray())\n",
    "evaluate(nb_clf, X_test_cv_vec.toarray(), y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simliar to the TFIDF experiments, the Naive Bayes algorithm had about a 10% drop in it's ability to explain the variance in data it had never seen before. We see the same healthy drop in F1 score by about 11%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost expects either a DataFrame or an Array, but not a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.386549Z",
     "start_time": "2022-11-17T07:09:06.803Z"
    }
   },
   "outputs": [],
   "source": [
    "# instatiating the cat boost algorithm\n",
    "cat_boost_clf = CatBoostClassifier(verbose = 0, \n",
    "                                  loss_function = 'Logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.387130Z",
     "start_time": "2022-11-17T07:09:06.804Z"
    }
   },
   "outputs": [],
   "source": [
    "# making a catboost grid \n",
    "cat_boost_grid = {'iterations': [5000, 6000, 7000],\n",
    " 'depth': [3, 4, 5],\n",
    " 'learning_rate': [0.01, 0.02, 0.03]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.387632Z",
     "start_time": "2022-11-17T07:09:06.806Z"
    }
   },
   "outputs": [],
   "source": [
    "#Applying classyfier and grid for the Gridsearch\n",
    "cb_gs_tfidf = GridSearchCV(estimator = cat_boost_clf, param_grid = cat_boost_grid, \n",
    "                           scoring = 'f1', cv = 5)\n",
    "\n",
    "#Fitting model with the training data\n",
    "cb_gs_tfidf.fit(X_train_tfidf_vec.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.388216Z",
     "start_time": "2022-11-17T07:09:06.808Z"
    }
   },
   "outputs": [],
   "source": [
    "# investigating the best params\n",
    "cb_gs_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.388823Z",
     "start_time": "2022-11-17T07:09:06.809Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds = get_cat_preds(cb_gs_tfidf, X_train_tfidf_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.389378Z",
     "start_time": "2022-11-17T07:09:06.811Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(cb_gs_tfidf, X_train_tfidf_vec.toarray(), y_train, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.390027Z",
     "start_time": "2022-11-17T07:09:06.812Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds = get_cat_preds(cb_gs_tfidf, X_test_tfidf_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.390699Z",
     "start_time": "2022-11-17T07:09:06.813Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(cb_gs_tfidf, X_test_tfidf_vec.toarray(), y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.392129Z",
     "start_time": "2022-11-17T07:09:06.815Z"
    }
   },
   "outputs": [],
   "source": [
    "#Applying pipeline and grid for the Gridsearch\n",
    "cb_gs_cv = GridSearchCV(estimator = cat_boost_clf, param_grid = cat_boost_grid, \n",
    "                        scoring = 'f1', cv = 5)\n",
    "\n",
    "#Fitting model with the training data\n",
    "cb_gs_cv.fit(X_train_cv_vec.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.392729Z",
     "start_time": "2022-11-17T07:09:06.816Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.393531Z",
     "start_time": "2022-11-17T07:09:06.818Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds = get_cat_preds(cb_gs_cv, X_train_cv_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.394321Z",
     "start_time": "2022-11-17T07:09:06.819Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(cb_gs_cv, X_train_cv_vec.toarray(), y_train, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.395163Z",
     "start_time": "2022-11-17T07:09:06.821Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds = get_cat_preds(cb_gs_cv, X_test_cv_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.395842Z",
     "start_time": "2022-11-17T07:09:06.822Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(cb_gs_cv, X_test_cv_vec.toarray(), y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.396713Z",
     "start_time": "2022-11-17T07:09:06.824Z"
    }
   },
   "outputs": [],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.397600Z",
     "start_time": "2022-11-17T07:09:06.825Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision_scores = []\n",
    "\n",
    "for x in reports:\n",
    "    for item in x.items():\n",
    "        if 'macro avg' in item:\n",
    "            precision_scores.append(item[1]['precision'])\n",
    "            \n",
    "            \n",
    "names = ['Random Forest TFIDF train', 'Random Forest TFIDF test',\n",
    "         'Random Forest CV train', 'Random Forest CV test',\n",
    "        'XG Boost TFIDF train', 'XG Boost TFIDF test',\n",
    "        'XG Boost CV train', 'XG Boost CV test',\n",
    "        'Naive Bayes TFIDF train', 'Naive Bayes TFIDF test',\n",
    "        'Naive Bayes CV train', 'Naive Bayes CV test',\n",
    "        'CatBoost TFIDF train', 'Catboost TFIDF test',\n",
    "        'Catboost CV train', 'Catboost CV test']\n",
    "\n",
    "precision_scores = pd.DataFrame(list(zip(names, precision_scores)))\n",
    "precision_scores.sort_values(by = [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I'll be choosing the Catboost algorithm and using the CV data since that did the best (although marginally.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.398366Z",
     "start_time": "2022-11-17T07:09:06.925Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = cb_gs_cv.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.399005Z",
     "start_time": "2022-11-17T07:09:06.927Z"
    }
   },
   "outputs": [],
   "source": [
    "best_cat = CatBoostClassifier('depth' = 5, 'iterations' = 5000, 'learning_rate' = 0.03, \n",
    "                    verbose = 0, loss_function = 'Logloss')\n",
    "best_cat.fit(X_train_cv_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.399595Z",
     "start_time": "2022-11-17T07:09:06.928Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds = best_cat.predict(X_valid_cv_vec)\n",
    "evaluate(best_cat, X_valid_cv_vec, y_valid, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T15:46:14.294821Z",
     "start_time": "2022-11-16T15:46:14.287163Z"
    }
   },
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.400368Z",
     "start_time": "2022-11-17T07:09:06.930Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(best_cat, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T01:34:48.077373Z",
     "start_time": "2022-11-10T01:34:48.067360Z"
    }
   },
   "source": [
    "## Explainer with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.401261Z",
     "start_time": "2022-11-17T07:09:06.932Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importances = best_cat.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.401994Z",
     "start_time": "2022-11-17T07:09:06.933Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens_by_name = tfidf_vectorizer.get_feature_names_out(X_train_tfidf_vec)\n",
    "tokens_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.402589Z",
     "start_time": "2022-11-17T07:09:06.935Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importances = list(zip(feature_importances, tokens_by_name))\n",
    "feature_importances_df = pd.DataFrame(feature_importances)\n",
    "feature_importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.403151Z",
     "start_time": "2022-11-17T07:09:06.936Z"
    }
   },
   "outputs": [],
   "source": [
    "only_import = feature_importances_df.loc[feature_importances_df[0] != 0.0]\n",
    "only_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.403823Z",
     "start_time": "2022-11-17T07:09:06.938Z"
    }
   },
   "outputs": [],
   "source": [
    "only_import[2] = only_import[0].astype(str) + ' ' + only_import[1]\n",
    "most_important_terms = sorted(only_import[2], reverse = True)\n",
    "top_50 = most_important_terms[:50]\n",
    "top_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.404464Z",
     "start_time": "2022-11-17T07:09:06.939Z"
    }
   },
   "outputs": [],
   "source": [
    "top_50_terms = [x.split(' ')[1] for x in top_50]\n",
    "top_50_terms_string = \" \".join(top_50_terms)\n",
    "top_50_terms_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainer with Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.405011Z",
     "start_time": "2022-11-17T07:09:06.941Z"
    }
   },
   "outputs": [],
   "source": [
    "X_sample_strings = [X[x] for x in range(10)]\n",
    "X_sample_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.405592Z",
     "start_time": "2022-11-17T07:09:06.943Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline_vectorizer, best_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.406128Z",
     "start_time": "2022-11-17T07:09:06.944Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_text\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "labels = ['Negative Sentiment', 'Positive Sentiment']\n",
    "explainer = lime.lime_text.LimeTextExplainer(class_names = labels)\n",
    "\n",
    "for x in X_sample_strings:\n",
    "    print(x)\n",
    "    exp = explainer.explain_instance(x, pipeline.predict_proba, num_features=5, top_labels=1)\n",
    "    exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.406710Z",
     "start_time": "2022-11-17T07:09:06.946Z"
    }
   },
   "outputs": [],
   "source": [
    "most_common_posi_words = most_common(pos_doc_string, 'Positive Sentiment')[0]\n",
    "most_common_posi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.407413Z",
     "start_time": "2022-11-17T07:09:06.947Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in most_common_posi_words:\n",
    "    exp = explainer.explain_instance(str(x), pipeline.predict_proba, num_features=50)\n",
    "    exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.408021Z",
     "start_time": "2022-11-17T07:09:06.949Z"
    }
   },
   "outputs": [],
   "source": [
    "most_common_neg_words = most_common(neg_doc_string, 'Negative Sentiment')[0]\n",
    "most_common_neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.408558Z",
     "start_time": "2022-11-17T07:09:06.950Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in most_common_neg_words:\n",
    "    exp = explainer.explain_instance(str(x), pipeline.predict_proba, num_features=50)\n",
    "    exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T07:09:55.409103Z",
     "start_time": "2022-11-17T07:09:06.952Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(top_50_terms_string, pipeline.predict_proba, num_features=50)\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: As we can see from our "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
